{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2636acf2-d2b7-453c-aacf-ea56dd809cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is the second step after receiving the data from the youtube api.\n",
    "This files extract the data and safes them once as csv and once as nested dictionary\n",
    "'''\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f112c8-dbde-486d-8a82-97d5d58b110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/raw/comments_dict_reichelt.json', 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "    data_reichelt = json.load(json_file)\n",
    "    \n",
    "with open('data/raw/video_stat_reichelt.json', 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "    stat_data_reichelt = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1735a4ae-a141-4778-ac76-f799ce24b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/raw/video_stat_dw.json', 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "    stat_data_dw = json.load(json_file)\n",
    "    \n",
    "with open('data/raw/comments_dict_dw.json', 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "    data_dw = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ca35fb-bee7-4571-a3c2-88c94e03749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/raw/video_stat_jung.json', 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "    stat_data_jung = json.load(json_file)\n",
    "    \n",
    "with open('data/raw/comments_dict_jung.json', 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "    data_jung = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bfd9316-9585-43be-b864-cfa66ba00113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/raw/vids.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add3f915-7a2d-4155-9fb7-8f27d90e3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(ChannelId,comments_data,vid):\n",
    "    '''\n",
    "    This function takes all json junks from the youtube api request and extracts important data to merge into a csv later on \n",
    "    '''\n",
    "    #list for comment csv\n",
    "    text = []\n",
    "    publishedAt = []\n",
    "    authorID = []\n",
    "    likeCount = [] \n",
    "    totalReplyCount = []\n",
    "    parentID = []\n",
    "    commentID = []\n",
    "    videoID = []\n",
    "    channelId = []\n",
    "    username = []\n",
    "\n",
    "    #list for video csv\n",
    "    videoPublishedAt = []\n",
    "    videolikeCount = [] \n",
    "    title = []\n",
    "    description = []\n",
    "    viewCount = []\n",
    "    likeCount = []\n",
    "    commentCount = []\n",
    "    videochannelId = []\n",
    "    videovideoID = []\n",
    "    channelName = []\n",
    "    transcript = []\n",
    "\n",
    "    yt_data = {\n",
    "       ChannelId: {}\n",
    "    }\n",
    "\n",
    "    for key, value in comments_data.items():\n",
    "        comments = {}\n",
    "\n",
    "        for i in value:\n",
    "            comment_id = i[\"id\"]\n",
    "            try:\n",
    "                comment_data = {\n",
    "                    \"publishedAt\": i[\"snippet\"]['topLevelComment'][\"snippet\"]['publishedAt'],\n",
    "                    \"text\": i[\"snippet\"]['topLevelComment'][\"snippet\"]['textOriginal'],\n",
    "                    \"authorID\": i[\"snippet\"]['topLevelComment'][\"snippet\"]['authorChannelId']['value'],\n",
    "                    \"likeCount\": i[\"snippet\"]['topLevelComment'][\"snippet\"]['likeCount'],\n",
    "                    \"totalReplyCount\": i[\"snippet\"]['totalReplyCount'],\n",
    "                    \"parentID\": 0\n",
    "                }\n",
    "\n",
    "                comments[comment_id] = comment_data\n",
    "\n",
    "                text.append(i[\"snippet\"]['topLevelComment'][\"snippet\"]['textOriginal'])\n",
    "                publishedAt.append(i[\"snippet\"]['topLevelComment'][\"snippet\"]['publishedAt'])\n",
    "                authorID.append(i[\"snippet\"]['topLevelComment'][\"snippet\"]['authorChannelId']['value'])\n",
    "                likeCount.append(i[\"snippet\"]['topLevelComment'][\"snippet\"]['likeCount'])\n",
    "                totalReplyCount.append( i[\"snippet\"]['totalReplyCount'])\n",
    "                parentID.append(0)\n",
    "                commentID.append(i[\"id\"])\n",
    "                videoID.append(key)\n",
    "                channelId.append(ChannelId)\n",
    "                username.append(i[\"snippet\"]['topLevelComment'][\"snippet\"]['authorDisplayName'])\n",
    "            except:\n",
    "                \n",
    "                comment_data = {\n",
    "                    \"publishedAt\": i[\"snippet\"]['topLevelComment'][\"snippet\"]['publishedAt'],\n",
    "                    \"text\": i[\"snippet\"]['topLevelComment'][\"snippet\"]['textOriginal'],\n",
    "                    \"authorID\": 0,\n",
    "                    \"likeCount\": i[\"snippet\"]['topLevelComment'][\"snippet\"]['likeCount'],\n",
    "                    \"totalReplyCount\": i[\"snippet\"]['totalReplyCount'],\n",
    "                    \"parentID\": 0\n",
    "                }\n",
    "\n",
    "                comments[comment_id] = comment_data\n",
    "\n",
    "                text.append(i[\"snippet\"]['topLevelComment'][\"snippet\"]['textOriginal'])\n",
    "                publishedAt.append(i[\"snippet\"]['topLevelComment'][\"snippet\"]['publishedAt'])\n",
    "                authorID.append(0)\n",
    "                likeCount.append(i[\"snippet\"]['topLevelComment'][\"snippet\"]['likeCount'])\n",
    "                totalReplyCount.append( i[\"snippet\"]['totalReplyCount'])\n",
    "                parentID.append(0)\n",
    "                commentID.append(i[\"id\"])\n",
    "                videoID.append(key)\n",
    "                channelId.append(ChannelId)\n",
    "                username.append(i[\"snippet\"]['topLevelComment'][\"snippet\"]['authorDisplayName'])\n",
    "                \n",
    "\n",
    "\n",
    "            #check for replies and extract them\n",
    "            if i[\"snippet\"]['totalReplyCount'] > 0:\n",
    "                for x in i[\"replies\"][\"comments\"]:\n",
    "                    try:\n",
    "                        reply_id = x[\"id\"]\n",
    "                        reply_data = {\n",
    "                            \"publishedAt\": x[\"snippet\"]['publishedAt'],\n",
    "                            \"text\": x[\"snippet\"]['textOriginal'],\n",
    "                            \"authorID\": x[\"snippet\"]['authorChannelId']['value'],\n",
    "                            \"likeCount\": x[\"snippet\"]['likeCount'],\n",
    "                            \"totalReplyCount\": 0,\n",
    "                            \"parentID\": x[\"snippet\"]['parentId']\n",
    "                        }\n",
    "\n",
    "                        comments[reply_id] = reply_data\n",
    "\n",
    "                        text.append(x[\"snippet\"]['textOriginal'])\n",
    "                        publishedAt.append(x[\"snippet\"]['publishedAt'])\n",
    "                        authorID.append(x[\"snippet\"]['authorChannelId']['value'])\n",
    "                        likeCount.append(x[\"snippet\"]['likeCount'])\n",
    "                        totalReplyCount.append(0)\n",
    "                        parentID.append(x[\"snippet\"]['parentId'])\n",
    "                        commentID.append(reply_id)\n",
    "                        videoID.append(key)\n",
    "                        channelId.append(ChannelId)\n",
    "                        username.append(x[\"snippet\"]['authorDisplayName'])\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "    for key, value in vid.items():\n",
    "        if value[\"items\"][0][\"id\"] == key:\n",
    "            j = value[\"items\"][0]\n",
    "            try:\n",
    "                vid_stat = {\n",
    "                    \"publishedAt\": j[\"snippet\"]['publishedAt'],\n",
    "                    \"title\": j[\"snippet\"]['title'],\n",
    "                    \"description\": j[\"snippet\"]['description'],\n",
    "                    \"viewCount\": j[\"statistics\"]['viewCount'],\n",
    "                    \"likeCount\": j[\"statistics\"]['likeCount'],\n",
    "                    \"commentCount\": j[\"statistics\"]['commentCount']\n",
    "                }\n",
    "\n",
    "\n",
    "                videoPublishedAt.append(j[\"snippet\"]['publishedAt'])\n",
    "                title.append(j[\"snippet\"]['title'])\n",
    "                description.append(j[\"snippet\"]['description'])\n",
    "                viewCount.append(j[\"statistics\"]['viewCount'])\n",
    "                videolikeCount.append(j[\"statistics\"]['likeCount'])\n",
    "                commentCount.append(j[\"statistics\"]['commentCount'])\n",
    "                videochannelId.append(ChannelId)\n",
    "                videovideoID.append(key)\n",
    "                channelName.append(j[\"snippet\"]['channelTitle'])\n",
    "                transcript.append(df.loc[df['video_id'] == key, 'transcript'].values[0])\n",
    "\n",
    "                    \n",
    "                \n",
    "            except:\n",
    "                vid_stat = {\n",
    "                    \"publishedAt\": j[\"snippet\"]['publishedAt'],\n",
    "                    \"title\": j[\"snippet\"]['title'],\n",
    "                    \"description\": j[\"snippet\"]['description'],\n",
    "                    \"viewCount\": j[\"statistics\"]['viewCount'],\n",
    "                    \"likeCount\": j[\"statistics\"]['likeCount'],\n",
    "                    \"commentCount\": len(comments_data[key])\n",
    "                }\n",
    "                    \n",
    "                videoPublishedAt.append(j[\"snippet\"]['publishedAt'])\n",
    "                title.append(j[\"snippet\"]['title'])\n",
    "                description.append(j[\"snippet\"]['description'])\n",
    "                viewCount.append(j[\"statistics\"]['viewCount'])\n",
    "                videolikeCount.append(j[\"statistics\"]['likeCount'])\n",
    "                commentCount.append(len(comments_data[key]))\n",
    "                videochannelId.append(ChannelId)\n",
    "                videovideoID.append(key)\n",
    "                channelName.append(j[\"snippet\"]['channelTitle'])\n",
    "                transcript.append(df.loc[df['video_id'] == key, 'transcript'].values[0])\n",
    "                    \n",
    "                    \n",
    "\n",
    "        yt_data[ChannelId][key] = [vid_stat, comments]\n",
    "\n",
    "    return yt_data, commentID, text, publishedAt, authorID, likeCount, totalReplyCount, parentID, videoID, channelId, username,  videoPublishedAt, videolikeCount, title, description, viewCount, videolikeCount, commentCount, videochannelId, videovideoID,channelName, transcript \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b633db5-ae07-4772-80d6-1af69f700768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Loop through every data and extract values, then merge listws to get combined data\n",
    "'''\n",
    "    \n",
    "channel_ids = [\"UCcoQ3WG2J_Xjwwyt-sJqh-w\", 'UCMIgOXM2JEQ2Pv2d0_PVfcg', 'UCv1WDP5EiipMQ__C4Cg6aow']\n",
    "comments_data =[data_reichelt,  data_dw, data_jung]\n",
    "vid_data = [stat_data_reichelt,stat_data_dw, stat_data_jung]\n",
    "\n",
    "merged_commentID = []\n",
    "merged_text = []\n",
    "merged_publishedAt = []\n",
    "merged_authorID = []\n",
    "merged_likeCount = []\n",
    "merged_totalReplyCount = []\n",
    "merged_parentID = []\n",
    "merged_videoID = []\n",
    "merged_channelId = []\n",
    "merged_username = []\n",
    "merged_videoPublishedAt = []\n",
    "merged_videolikeCount = []\n",
    "merged_title = []\n",
    "merged_description = []\n",
    "merged_viewCount = []\n",
    "merged_commentCount = []\n",
    "merged_videochannelId = []\n",
    "merged_videovideoID = []\n",
    "merged_channelName = []\n",
    "merged_transcript = []\n",
    "\n",
    "\n",
    "for i in range(len(channel_ids)):\n",
    "    print(i)\n",
    "    yt_data, commentID, text, publishedAt, authorID, likeCount, totalReplyCount, parentID, videoID, channelId, username, videoPublishedAt, videolikeCount, title, description, viewCount, videolikeCount, commentCount, videochannelId, videovideoID, channelName, transcript = cleanData(channel_ids[i], comments_data[i], vid_data[i])\n",
    "\n",
    "    # Merge the lists\n",
    "    merged_commentID.extend(commentID)\n",
    "    merged_text.extend(text)\n",
    "    merged_publishedAt.extend(publishedAt)\n",
    "    merged_authorID.extend(authorID)\n",
    "    merged_likeCount.extend(likeCount)\n",
    "    merged_totalReplyCount.extend(totalReplyCount)\n",
    "    merged_parentID.extend(parentID)\n",
    "    merged_videoID.extend(videoID)\n",
    "    merged_channelId.extend(channelId)\n",
    "    merged_username.extend(username)\n",
    "    merged_videoPublishedAt.extend(videoPublishedAt)\n",
    "    merged_videolikeCount.extend(videolikeCount)\n",
    "    merged_title.extend(title)\n",
    "    merged_description.extend(description)\n",
    "    merged_viewCount.extend(viewCount)\n",
    "    merged_commentCount.extend(commentCount)\n",
    "    merged_videochannelId.extend(videochannelId)\n",
    "    merged_videovideoID.extend(videovideoID)\n",
    "    merged_channelName.extend(channelName)\n",
    "    merged_transcript.extend(transcript)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea73791-59f5-4572-9c80-4c867ee55b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a list of rows, where each row is a list of attributes\n",
    "rows = list(zip(merged_commentID, \n",
    "                merged_text, \n",
    "                merged_publishedAt, \n",
    "                merged_authorID, \n",
    "                merged_likeCount, \n",
    "                merged_totalReplyCount,\n",
    "                merged_parentID, \n",
    "                merged_videoID, \n",
    "                merged_channelId,\n",
    "                merged_username))\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file = \"data/raw/comments.csv\"\n",
    "\n",
    "# Write the rows to the CSV file with UTF-8 encoding\n",
    "with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"commentID\", \"text\", \"publishedAt\", \"authorID\", \"likeCount\", \"totalReplyCount\", \"parentID\", \"videoID\", \"channelId\", \"username\"])  # Write header\n",
    "    writer.writerows(rows)  # Write data rows\n",
    "\n",
    "print(\"CSV file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967eefe5-22e9-4014-9fe7-349aeba74fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a list of rows, where each row is a list of attributes\n",
    "rows = list(\n",
    "    zip(\n",
    "        merged_videoPublishedAt,\n",
    "        merged_videolikeCount,\n",
    "        merged_title,\n",
    "        merged_description,\n",
    "        merged_viewCount,\n",
    "        merged_videolikeCount,\n",
    "        merged_commentCount,\n",
    "        merged_videochannelId,\n",
    "        merged_videovideoID,\n",
    "        merged_channelName,\n",
    "        merged_transcript\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file = \"data/raw/videos.csv\"\n",
    "\n",
    "# Write the rows to the CSV file with UTF-8 encoding\n",
    "with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(\n",
    "        [\n",
    "            \"videoPublishedAt\",\n",
    "            \"videolikeCount\",\n",
    "            \"title\",\n",
    "            \"description\",\n",
    "            \"viewCount\",\n",
    "            \"likeCount\",\n",
    "            \"commentCount\",\n",
    "            \"videochannelId\",\n",
    "            \"videovideoID\",\n",
    "            \"channelName\",\n",
    "            \"transcript\"\n",
    "        ]\n",
    "    )  # Write header\n",
    "    writer.writerows(rows)  # Write data rows\n",
    "\n",
    "print(\"CSV file created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
